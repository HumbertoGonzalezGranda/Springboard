{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/notebooks/headers/AutoAI-Banner_Experiment-Notebook.png)\n",
    "# Experiment Notebook - AutoAI Notebook v1.15.3\n",
    "\n",
    "\n",
    "This notebook contains the steps and code to demonstrate support of AutoAI experiments in Watson Machine Learning service. It introduces Python API commands for data retrieval, training experiments, persisting pipelines, testing pipelines, refining pipelines, and scoring the resulting model.\n",
    "\n",
    "**Note:** Notebook code generated using AutoAI will execute successfully. If code is modified or reordered, there is no guarantee it will successfully execute. For details, see: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Saving an Auto AI experiment as a notebook</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some familiarity with Python is helpful. This notebook uses Python 3.8 and `ibm_watson_machine_learning` package.\n",
    "\n",
    "\n",
    "## Notebook goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "-  Defining an AutoAI experiment\n",
    "-  Training AutoAI models \n",
    "-  Comparing trained models\n",
    "-  Deploying the model as a web service\n",
    "-  Scoring the model to generate predictions.\n",
    "\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "**[Setup](#setup)**<br>\n",
    "&nbsp;&nbsp;[Package installation](#install)<br>\n",
    "&nbsp;&nbsp;[Watson Machine Learning connection](#connection)<br>\n",
    "**[Experiment configuration](#configuration)**<br>\n",
    "&nbsp;&nbsp;[Experiment metadata](#metadata)<br>\n",
    "**[Working with completed AutoAI experiment](#work)**<br>\n",
    "&nbsp;&nbsp;[Get fitted AutoAI optimizer](#get)<br>\n",
    "&nbsp;&nbsp;[Pipelines comparison](#comparison)<br>\n",
    "&nbsp;&nbsp;[Get pipeline as scikit-learn pipeline model](#get_pipeline)<br>\n",
    "&nbsp;&nbsp;[Inspect pipeline](#inspect_pipeline)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Visualize pipeline model](#visualize)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Preview pipeline model as python code](#preview)<br>\n",
    "**[Deploy and Score](#scoring)**<br>\n",
    "&nbsp;&nbsp;[Working with spaces](#working_spaces)<br>\n",
    "**[Running AutoAI experiment with Python API](#run)**<br>\n",
    "**[Clean up](#cleanup)**<br>\n",
    "**[Next steps](#next_steps)**<br>\n",
    "**[Copyrights](#copyrights)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install\"></a>\n",
    "## Package installation\n",
    "Before you use the sample code in this notebook, install the following packages:\n",
    " - ibm-watson-machine-learning,\n",
    " - autoai-libs,\n",
    " - lale,\n",
    " - scikit-learn,\n",
    " - xgboost,\n",
    " - lightgbm,\n",
    " - snapml.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'tail' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'tail' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the file specified.\n",
      "'tail' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'tail' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'tail' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'tail' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install ibm-watson-machine-learning | tail -n 1\n",
    "!pip install -U autoai-libs==1.12.11 | tail -n 1\n",
    "!pip install -U 'lale>=0.5.3,<0.6' | tail -n 1\n",
    "!pip install -U scikit-learn==0.23.2 | tail -n 1\n",
    "!pip install -U xgboost==1.3.3 | tail -n 1\n",
    "!pip install -U lightgbm==3.1.1 | tail -n 1\n",
    "!pip install -U snapml==1.7.4  | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"configuration\"></a>\n",
    "# Experiment configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"metadata\"></a>\n",
    "## Experiment metadata\n",
    "This cell defines the metadata for the experiment, including: training_data_reference, training_result_reference, experiment_metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ibm_watson_machine_learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4fa95c01fd86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mibm_watson_machine_learning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mibm_watson_machine_learning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mS3Connection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS3Location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m training_data_reference = [\n\u001b[0;32m      5\u001b[0m     DataConnection(\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ibm_watson_machine_learning'"
     ]
    }
   ],
   "source": [
    "from ibm_watson_machine_learning.helpers import DataConnection\n",
    "from ibm_watson_machine_learning.helpers import S3Connection, S3Location\n",
    "\n",
    "training_data_reference = [\n",
    "    DataConnection(\n",
    "    connection=S3Connection(\n",
    "        api_key='P5E4MnM3UlfqJ5lWsy1Ha0L9tpM3ApnzSBIF89CdTe3e',\n",
    "        auth_endpoint='https://iam.bluemix.net/oidc/token/',\n",
    "        endpoint_url='https://s3.us.cloud-object-storage.appdomain.cloud'\n",
    "    ),\n",
    "        location=S3Location(\n",
    "            bucket='airbnblalogprice-donotdelete-pr-4zhtgsilso0roa',\n",
    "            path='train.csv'\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "training_result_reference = DataConnection(\n",
    "    connection=S3Connection(\n",
    "        api_key='P5E4MnM3UlfqJ5lWsy1Ha0L9tpM3ApnzSBIF89CdTe3e',\n",
    "        auth_endpoint='https://iam.bluemix.net/oidc/token/',\n",
    "        endpoint_url='https://s3.us.cloud-object-storage.appdomain.cloud'\n",
    "    ),\n",
    "    location=S3Location(\n",
    "        bucket='airbnblalogprice-donotdelete-pr-4zhtgsilso0roa',\n",
    "        path='auto_ml/a3e750c7-121b-479e-b926-fc7bebbf9da8/wml_data/31f43d63-5aab-453f-b309-329253720c88/data/automl',\n",
    "        model_location='auto_ml/a3e750c7-121b-479e-b926-fc7bebbf9da8/wml_data/31f43d63-5aab-453f-b309-329253720c88/data/automl/pre_hpo_d_output/Pipeline1/model.pickle',\n",
    "        training_status='auto_ml/a3e750c7-121b-479e-b926-fc7bebbf9da8/wml_data/31f43d63-5aab-453f-b309-329253720c88/training-status.json'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment_metadata = dict(\n",
    "    prediction_type='regression',\n",
    "    prediction_column='log_price',\n",
    "    holdout_size=0.1,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    csv_separator=',',\n",
    "    random_state=33,\n",
    "    max_number_of_estimators=4,\n",
    "    training_data_reference=training_data_reference,\n",
    "    training_result_reference=training_result_reference,\n",
    "    include_only_estimators=['RandomForestRegressor', 'DecisionTreeRegressor', 'Ridge', 'ExtraTreesRegressor', 'LinearRegression', 'XGBRegressor', 'LGBMRegressor', 'SnapDecisionTreeRegressor', 'SnapRandomForestRegressor', 'SnapBoostingMachineRegressor', 'GradientBoostingRegressor'],\n",
    "    deployment_url='https://us-south.ml.cloud.ibm.com',\n",
    "    project_id='d83824b9-44d4-45d6-8ed9-b7ee7e9262a5',\n",
    "    drop_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"connection\"></a>\n",
    "## Watson Machine Learning connection\n",
    "\n",
    "This cell defines the credentials required to work with the Watson Machine Learning service.\n",
    "\n",
    "**Action**: Please provide IBM Cloud apikey following [docs](https://cloud.ibm.com/docs/account?topic=account-userapikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "api_key = 'PUT_YOUR_APIKEY_HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": api_key,\n",
    "    \"url\": experiment_metadata['deployment_url']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"work\"></a>\n",
    "\n",
    "\n",
    "# Working with the completed AutoAI experiment\n",
    "\n",
    "This cell imports the pipelines generated for the experiment so they can be compared to find the optimal pipeline to save as a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get\"></a>\n",
    "\n",
    "\n",
    "## Get fitted AutoAI optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.experiment import AutoAI\n",
    "\n",
    "pipeline_optimizer = AutoAI(wml_credentials, project_id=experiment_metadata['project_id']).runs.get_optimizer(metadata=experiment_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `get_params()`- to retrieve configuration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_optimizer.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"comparison\"></a>\n",
    "## Pipelines comparison\n",
    "\n",
    "Use the `summary()` method to list trained pipelines and evaluation metrics information in\n",
    "the form of a Pandas DataFrame. You can use the DataFrame to compare all discovered pipelines and select the one you like for further testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "summary = pipeline_optimizer.summary()\n",
    "best_pipeline_name = list(summary.index)[0]\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get_pipeline\"></a>\n",
    "### Get pipeline as scikit-learn pipeline model\n",
    "\n",
    "After you compare the pipelines, download and save a scikit-learn pipeline model object from the\n",
    "AutoAI training job.\n",
    "\n",
    "**Tip:** To get a specific pipeline pass the pipeline name in:\n",
    "```\n",
    "pipeline_optimizer.get_pipeline(pipeline_name=pipeline_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model = pipeline_optimizer.get_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, check features importance for selected pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_optimizer.get_pipeline_details()['features_importance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** If you want to check all model evaluation metrics-details, use:\n",
    "```\n",
    "pipeline_optimizer.get_pipeline_details()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"inspect_pipeline\"></a>\n",
    "## Inspect pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualize\"></a>\n",
    "### Visualize pipeline model\n",
    "\n",
    "Preview pipeline model stages as a graph. Each node's name links to a detailed description of the stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preview\"></a>\n",
    "### Preview pipeline model as Python code\n",
    "In the next cell, you can preview the saved pipeline model as Python code.  \n",
    "You can review the exact steps used to create the model.\n",
    "\n",
    "**Note:** If you want to get sklearn representation, add the following parameter to `pretty_print` call: `astype='sklearn'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model.pretty_print(combinators=False, ipython_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the `predict` method\n",
    "If you want to get a prediction using pipeline model object, call `pipeline_model.predict()`.\n",
    "\n",
    "**Note:** If you want to work with pure sklearn model:\n",
    " - add the following parameter to `get_pipeline` call: `astype='sklearn'`,\n",
    " - or `scikit_learn_pipeline = pipeline_model.export_to_sklearn_pipeline()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scoring\"></a>\n",
    "## Deploy and Score\n",
    "\n",
    "In this section you will learn how to deploy and score the model as a web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"working_spaces\"></a>\n",
    "### Working with spaces\n",
    "\n",
    "In this section you will specify a deployment space for organizing the assets for deploying and scoring the model. If you do not have an existing space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create a new space, following these steps:\n",
    "\n",
    "- Click **New Deployment Space**.\n",
    "- Create an empty space.\n",
    "- Select Cloud Object Storage.\n",
    "- Select Watson Machine Learning instance and press **Create**.\n",
    "- Copy `space_id` and paste it below.\n",
    "\n",
    "**Tip**: You can also use the API to prepare the space for your work. Learn more [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n",
    "\n",
    "**Action**: assign or update space ID below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_space_id = \"PUT_YOUR_TARGET_SPACE_ID_HERE\"\n",
    "\n",
    "from ibm_watson_machine_learning.deployment import WebService\n",
    "\n",
    "service = WebService(\n",
    "    source_wml_credentials=wml_credentials,\n",
    "    target_wml_credentials=wml_credentials,\n",
    "    source_project_id=experiment_metadata['project_id'],\n",
    "    target_space_id=target_space_id\n",
    ")\n",
    "service.create(\n",
    "    model=best_pipeline_name,\n",
    "    metadata=experiment_metadata,\n",
    "    deployment_name='Best_pipeline_webservice'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `print` method for the deployment object to show basic information about the service: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show all available information about the deployment use the `.get_params()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "service.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring of webservice\n",
    "You can make scoring request by calling `score()` on the deployed pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to work with the web service in an external Python application,follow these steps to retrieve the service object:\n",
    "\n",
    " - Initialize the service by `service = WebService(wml_credentials)`\n",
    " - Get deployment_id by `service.list()` method\n",
    " - Get webservice object by `service.get('deployment_id')` method\n",
    "\n",
    "After that you can call `service.score(score_records_df)` method. The `score()` method accepts `pandas.DataFrame` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "### Deleting deployment\n",
    "You can delete the existing deployment by calling the `service.delete()` command.\n",
    "To list the existing web services, use `service.list()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"run\"></a>\n",
    "\n",
    "## Running AutoAI experiment with Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to run the AutoAI experiment using the Python API, follow these. The experiment settings were generated basing on parameters set in the AutoAI UI.\n",
    " - Go to your COS dashboard.\n",
    " - In Service credentials tab, click New Credential.\n",
    " - Add the inline configuration parameter: `{“HMAC”:true}`, click Add.\n",
    "This configuration parameter adds the following section to the instance credentials, (for use later in this notebook):\n",
    "```\n",
    "”cos_hmac_keys”: {\n",
    "      “access_key_id”: “***“,\n",
    "      “secret_access_key”: “***”\n",
    " }\n",
    " ```\n",
    "\n",
    "**Action**: Please provide cos credentials in following cells.\n",
    "\n",
    "- Use provided markdown cells to run code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "```\n",
    "from ibm_watson_machine_learning.experiment import AutoAI\n",
    "\n",
    "experiment = AutoAI(wml_credentials, project_id=experiment_metadata['project_id'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#@hidden_cell\n",
    "cos_hmac_keys = {\n",
    "    \"access_key_id\": \"PLACE_YOUR_ACCESS_KEY_ID_HERE\",\n",
    "    \"secret_access_key\": \"PLACE_YOUR_SECRET_ACCESS_KEY_HERE\"\n",
    "  }\n",
    "  \n",
    "cos_api_key = \"PLACE_YOUR_API_KEY_HERE\"\n",
    "OPTIMIZER_NAME = 'custom_name'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "```\n",
    "from ibm_watson_machine_learning.helpers import DataConnection\n",
    "from ibm_watson_machine_learning.helpers import S3Connection, S3Location\n",
    "\n",
    "training_data_reference = [\n",
    "    DataConnection(\n",
    "    connection=S3Connection(\n",
    "        api_key='P5E4MnM3UlfqJ5lWsy1Ha0L9tpM3ApnzSBIF89CdTe3e',\n",
    "        auth_endpoint='https://iam.bluemix.net/oidc/token/',\n",
    "        endpoint_url='https://s3.us.cloud-object-storage.appdomain.cloud',\n",
    "        access_key_id = cos_hmac_keys['access_key_id'],\n",
    "        secret_access_key = cos_hmac_keys['secret_access_key']\n",
    "    ),\n",
    "        location=S3Location(\n",
    "            bucket='airbnblalogprice-donotdelete-pr-4zhtgsilso0roa',\n",
    "            path='train.csv'\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "training_result_reference = DataConnection(\n",
    "    connection=S3Connection(\n",
    "        api_key=cos_api_key,\n",
    "        auth_endpoint='https://iam.bluemix.net/oidc/token/',\n",
    "        endpoint_url='https://s3.us.cloud-object-storage.appdomain.cloud',\n",
    "        access_key_id = cos_hmac_keys['access_key_id'],\n",
    "        secret_access_key = cos_hmac_keys['secret_access_key']\n",
    "    ),\n",
    "    location=S3Location(\n",
    "        bucket='airbnblalogprice-donotdelete-pr-4zhtgsilso0roa',\n",
    "        path='auto_ml/a3e750c7-121b-479e-b926-fc7bebbf9da8/wml_data/31f43d63-5aab-453f-b309-329253720c88/data/automl',\n",
    "        model_location='auto_ml/a3e750c7-121b-479e-b926-fc7bebbf9da8/wml_data/31f43d63-5aab-453f-b309-329253720c88/data/automl/pre_hpo_d_output/Pipeline1/model.pickle',\n",
    "        training_status='auto_ml/a3e750c7-121b-479e-b926-fc7bebbf9da8/wml_data/31f43d63-5aab-453f-b309-329253720c88/training-status.json'\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new pipeline optimizer will be created and training will be triggered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%raw\n"
    }
   },
   "source": [
    "```\n",
    "pipeline_optimizer = experiment.optimizer(\n",
    "    name=OPTIMIZER_NAME,\n",
    "    prediction_type=experiment_metadata['prediction_type'],\n",
    "    prediction_column=experiment_metadata['prediction_column'],\n",
    "    scoring=experiment_metadata['scoring'],\n",
    "    holdout_size=experiment_metadata['holdout_size'],\n",
    "    csv_separator=experiment_metadata['csv_separator'],\n",
    "    drop_duplicates=experiment_metadata['drop_duplicates'],\n",
    "    include_only_estimators=experiment_metadata['include_only_estimators']\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pipeline_optimizer.fit(\n",
    "    training_data_reference=training_data_reference,\n",
    "    training_results_reference=training_result_reference,\n",
    "    background_mode=False,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"next_steps\"></a>\n",
    "# Next steps\n",
    "\n",
    "#### [Online Documentation](https://www.ibm.com/cloud/watson-studio/autoai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"copyrights\"></a>\n",
    "### Copyrights\n",
    "\n",
    "Licensed Materials - Copyright © 2021 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
    "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
    "\n",
    "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
    "\n",
    "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\">License Terms</a>  \n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
